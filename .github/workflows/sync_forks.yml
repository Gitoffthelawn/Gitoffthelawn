name: Safe Sync Forks

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  sync-forks:
    runs-on: ubuntu-latest
    steps:
      - name: Sync All Forks
        env:
          GH_TOKEN: ${{ secrets.SYNC_TOKEN }}
        run: |
          cat << 'EOF' > sync.js
          const { execSync } = require('child_process');
          const fs = require('fs');

          async function run() {
            let stats = { total: 0, synced: 0, noChange: 0, blocked: 0, failed: 0 };
            let tableRows = "| Repository | Status | Details |\n| :--- | :--- | :--- |\n";
            let failureLog = "\n### ‚ö†Ô∏è Failure Details\n| Repository | Error Message |\n| :--- | :--- |\n";
            let hasFailures = false;
            let hasTableEntries = false;

            try {
              // 1. Quota Check (Start)
              const quotaStart = JSON.parse(execSync('gh api rate_limit').toString());
              const remainingStart = quotaStart.resources.core.remaining;

              console.log("Deep Scanning for all owned repositories...");
              
              // We removed all filters except owner and visibility=all. 
              // This is the "loudest" possible request for a Classic PAT.
              execSync(`gh api "user/repos?per_page=100&affiliation=owner&visibility=all" --paginate > forks_raw.json`);
              
              const rawData = fs.readFileSync('forks_raw.json', 'utf8').trim();
              if (!rawData || rawData === "[]") {
                throw new Error("The API returned zero repositories. This indicates the TOKEN is authorized but cannot see your account data.");
              }

              const sanitized = "[" + rawData.replace(/\]\s*\[/g, ',') + "]";
              const allRepos = JSON.parse(sanitized);
              
              const targetForks = allRepos.filter(f => f.fork === true);
              console.log(`API found ${allRepos.length} total repos. ${targetForks.length} are forks.`);

              if (targetForks.length === 0) {
                const sample = allRepos.slice(0, 5).map(r => r.full_name).join(", ");
                let diag = `### üìä API Quota\n- **Remaining:** ${remainingStart} / 5000\n\n`;
                diag += `### üîÑ Sync Activity Report\n- **Total Forks Found:** 0\n\n`;
                diag += `**Diagnostic:** The API sees ${allRepos.length} repos. Sample: \`${sample}\`.\n\n`;
                diag += `If these aren't your 1,500 repos, your PAT may be authorized for a different 'context' or 'organization'.`;
                fs.appendFileSync(process.env.GITHUB_STEP_SUMMARY, diag);
                return;
              }

              // 2. Process the Forks
              for (const fork of targetForks) {
                stats.total++;
                const name = fork.full_name;
                const mySize = fork.size;

                try {
                  const parentData = JSON.parse(execSync(`gh api "repos/${name}" --silent`).toString());
                  const parent = parentData.parent;

                  if (!parent) {
                    failureLog += `| ${name} | Parent info missing/private |\n`;
                    stats.failed++;
                    hasFailures = true;
                    continue;
                  }

                  // Sanity Check: Parent size vs Fork size
                  if (parent.size < (mySize / 2) && mySize > 100) {
                    tableRows += `| ${name} | üõë **BLOCKED** | Size Trigger: Parent ${parent.size}KB vs Fork ${mySize}KB |\n`;
                    stats.blocked++;
                    hasTableEntries = true;
                  } else {
                    // Sync Attempt
                    try {
                      const syncOut = execSync(`gh repo sync "${name}" --force=false 2>&1`).toString();
                      if (syncOut.includes("already up to date")) {
                        stats.noChange++;
                      } else {
                        tableRows += `| ${name} | ‚úÖ Synced | Successfully updated |\n`;
                        stats.synced++;
                        hasTableEntries = true;
                      }
                    } catch (syncErr) {
                      const errMsg = syncErr.stdout ? syncErr.stdout.toString().split('\n')[0] : "Sync conflict";
                      tableRows += `| ${name} | ‚ùå Failed | See failure log |\n`;
                      failureLog += `| ${name} | ${errMsg.replace(/\|/g, '-')} |\n`;
                      stats.failed++;
                      hasFailures = true;
                      hasTableEntries = true;
                    }
                  }
                } catch (e) { stats.failed++; }

                if (stats.total % 100 === 0) console.log(`Processed ${stats.total}...`);
                await new Promise(r => setTimeout(r, 120)); // Gentle pacing
              }

              // 3. Final Quota & Summary
              const quotaEnd = JSON.parse(execSync('gh api rate_limit').toString());
              let finalSummary = `### üìä API Quota\n- **Start:** ${remainingStart}\n- **End:** ${quotaEnd.resources.core.remaining}\n\n`;
              finalSummary += `### üîÑ Sync Activity Report\n` +
                `- **Total Forks:** ${stats.total}\n` +
                `- **Synced:** ${stats.synced} | **Safety Blocked:** ${stats.blocked} | **Errors:** ${stats.failed}\n` +
                `- **Already Up-to-Date:** ${stats.noChange}\n\n`;

              if (hasTableEntries) finalSummary += tableRows;
              if (hasFailures) finalSummary += failureLog;

              fs.appendFileSync(process.env.GITHUB_STEP_SUMMARY, finalSummary);

            } catch (err) {
              fs.appendFileSync(process.env.GITHUB_STEP_SUMMARY, `### ‚ùå Fatal Error\n${err.message}`);
              process.exit(1);
            }
          }
          run();
          EOF
          
          node sync.js
