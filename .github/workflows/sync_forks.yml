name: Safe Sync Forks

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  sync-forks:
    runs-on: ubuntu-latest
    steps:
      - name: Sync All Forks
        env:
          GH_TOKEN: ${{ secrets.SYNC_TOKEN }}
        run: |
          cat << 'EOF' > sync.js
          const { execSync } = require('child_process');
          const fs = require('fs');

          async function run() {
            let stats = { total: 0, synced: 0, noChange: 0, blocked: 0, failed: 0 };
            let tableRows = "| Repository | Status | Details |\n| :--- | :--- | :--- |\n";
            let failureLog = "### âš ï¸ Failure Details\n| Repository | Error Message |\n| :--- | :--- |\n";
            let hasFailures = false;
            let hasTableEntries = false;

            try {
              console.log("Fetching list of forks to disk (bypassing buffer limits)...");
              const user = JSON.parse(execSync('gh api user').toString()).login;
              
              // Direct shell redirection to file handles any number of repos
              execSync(`gh api "users/${user}/repos?per_page=100" --paginate > forks_raw.json`);
              
              const rawData = fs.readFileSync('forks_raw.json', 'utf8').trim();
              if (!rawData) throw new Error("API returned no data.");

              // Handle paginated JSON arrays (stitches ][ into ,)
              const sanitized = "[" + rawData.replace(/\]\s*\[/g, ',') + "]";
              const forks = JSON.parse(sanitized);
              const targetForks = forks.filter(f => f.fork === true);
              
              console.log(`Found ${targetForks.length} forks. Processing...`);

              for (const fork of targetForks) {
                stats.total++;
                const name = fork.full_name;
                const mySize = fork.size;

                try {
                  // 1. Get Parent Info
                  const parentData = JSON.parse(execSync(`gh api "repos/${name}" --silent`).toString());
                  const parent = parentData.parent;

                  if (!parent) {
                    failureLog += `| ${name} | Upstream parent no longer exists or is private |\n`;
                    stats.failed++;
                    hasFailures = true;
                    continue;
                  }

                  const parentSize = parent.size;
                  const threshold = mySize / 2;

                  // 2. Sanity Check
                  if (parentSize < threshold && mySize > 100) {
                    tableRows += `| ${name} | ðŸ›‘ **BLOCKED** | Parent size (${parentSize}KB) < 50% of fork (${mySize}KB) |\n`;
                    stats.blocked++;
                    hasTableEntries = true;
                  } else {
                    // 3. Sync Attempt
                    try {
                      const syncOut = execSync(`gh repo sync "${name}" --force=false 2>&1`).toString();
                      if (syncOut.includes("already up to date")) {
                        stats.noChange++;
                      } else {
                        tableRows += `| ${name} | âœ… Synced | Successfully updated |\n`;
                        stats.synced++;
                        hasTableEntries = true;
                      }
                    } catch (syncErr) {
                      const errMsg = syncErr.stdout ? syncErr.stdout.toString().split('\n')[0] : "Merge conflict or scope issue";
                      tableRows += `| ${name} | âŒ Failed | See failure log below |\n`;
                      failureLog += `| ${name} | ${errMsg.replace(/\|/g, '-')} |\n`;
                      stats.failed++;
                      hasFailures = true;
                      hasTableEntries = true;
                    }
                  }
                } catch (e) {
                  failureLog += `| ${name} | API error: ${e.message} |\n`;
                  stats.failed++;
                  hasFailures = true;
                }

                if (stats.total % 100 === 0) console.log(`Processed ${stats.total}...`);
                await new Promise(r => setTimeout(r, 100)); // Respect API limits
              }

              // Build Final Summary
              let finalSummary = `### ðŸ”„ Sync Activity Report\n` +
                `- **Total Forks:** ${stats.total}\n` +
                `- **Synced:** ${stats.synced} | **Safety Blocked:** ${stats.blocked} | **Errors:** ${stats.failed}\n` +
                `- **Already Up-to-Date:** ${stats.noChange}\n\n`;

              if (hasTableEntries) {
                finalSummary += tableRows + "\n\n";
              } else {
                finalSummary += "_All repositories are currently synchronized or skipped._\n\n";
              }

              if (hasFailures) {
                finalSummary += failureLog;
              }

              fs.appendFileSync(process.env.GITHUB_STEP_SUMMARY, finalSummary);
              console.log("Sync process completed successfully.");

            } catch (err) {
              console.error("Fatal Error:", err.message);
              process.exit(1);
            }
          }
          run();
          EOF
          
          node sync.js
